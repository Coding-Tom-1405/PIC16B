[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/bruin/HW 4/index.html",
    "href": "posts/bruin/HW 4/index.html",
    "title": "Homework 4: Matrix Multiplication and Jax Numpy (Heat Diffusion)",
    "section": "",
    "text": "In this blog post, we will be going over how to use numpy arrays as well as comparing special tools to work with linear algebra. For our example, we will be conducting a simulation of two-dimensional heat diffusion maps.\nBecause we will be working with numpy as well as data visualization, we will need to import both numpy as well as pyplot.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nFor our 2D-heat diffusion maps, we will be using the following parameters:\n\nN = 101\nepsilon = 0.2\niters = 2700\n\nHere, our N represents the size of our array (meaning there will be N^2 values in our array) epsilon represents the “heaviness / stability” of each of our update, and iters represents the amount of iterations our simulation will run.\nFirst, we will need to create an an initial heatmap to iterate and update upon. We can create an initial N x N empty grid with a singular unit of heat at the center with the following line of code:\n\nu0 = np.zeros((N, N))              # Creating NxN numpy array with entries of 0\nu0[int(N/2), int(N/2)] = 1.0       # Assigning the midpoint value of initial array to 1\nplt.imshow(u0)                     # Plotting numpy array with the 1 unit of heat at midpoint\n\n\n\n\n\n\n\n\nGreat! Now that we have our initical condition heatmap, we can using different methods to update it.\n\nMatrix Multiplication\nThe first method we will use is matrix multiplication. Essentially, we want to construct an updating matrix A that will act upon the flattened version of u which will be iterated and updated each time.\nThus, the first function we want to create is for constructing our update matrix A (this matrix is called a finite difference matrix). We want our update in discrete time to be represented by the following function:\n\n\n\nScreenshot 2024-02-23 1.31.17 PM.png\n\n\nThus, we want our updating matrix A to represent the paranthesis part that is multiplied to epsilon.\n\n\n\nScreenshot 2024-02-23 1.30.29 PM.png\n\n\nHere, each u will represent a diagonal in our matrix: * u[i+1][j]: represents nth upper diagonal * u[i-1][j]: represents nth lower diagonal * u[i][j+1]: represents 1st upper diagonal * u[i][j-1]: represents 1st lower diagonal * u[i][j]: main diagonal\nWith this information, we can now create our function to account for the desired grid size N, which should look something like this:\n\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\nimport sys\nsys.path.append('/content/gdrive/My Drive')\nimport inspect\nfrom heat_equation import get_A\nprint(inspect.getsource(get_A))\n\nDrive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\ndef get_A(N):\n  \"\"\"Creates a 2D finite difference matrix by adjusting the diagonal entries\n  Args:\n       N: Integer representing size of desired matrix\n\n  Returns:\n       N x N adjusting matrix.\n  \"\"\"\n  # Getting total number of grid points\n  n = N * N\n  # Creating list with representative diagonals\n  diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n\n  # Adjusting diagonals to account periodic 0's\n  diagonals[1][(N-1)::N] = 0\n  diagonals[2][(N-1)::N] = 0\n\n  # Constructing finite difference matrix\n  A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n  return A\n\n\n\nNow that we have our function, let’s see what our function looks like with a test value parameter. For simplicity, we will use 3.\n\nget_A(3)\n\narray([[-4.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n       [ 1., -4.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n       [ 0.,  1., -4.,  0.,  0.,  1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0., -4.,  1.,  0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  1., -4.,  1.,  0.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.,  1., -4.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  1.,  0.,  0., -4.,  1.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.,  0.,  1., -4.,  1.],\n       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  1., -4.]])\n\n\nOur code outputted the matrix that we were looking for. Now, we can start on our next step: updating u.\nTo match the discrete time update equation, we want to take into account 3 parameters: our update matrix A, the iterated matrix u, and our “scaling/stability” value epsilon. Because we already have all the components of the equation. We can just type out the equation in our function. So our function should look something like this:\n\nfrom heat_equation import advance_time_matvecmul\nimport inspect\nprint(inspect.getsource(advance_time_matvecmul))\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]                                        # Calculating size of grid\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))   # Flattening 2D grid 'u', Matrix mult. with\n                                                          # A, Reshaping back to original grade shape,\n                                                          # Updating 'u' with matrix multiplication + epsilon\n    return u\n\n\n\nWith both of these equations, we can now run our iterations.\nFirst, because we are comparing different methods for creating identical heatmaps, we want to import time in order to see execution time.\n\nimport time\n\nNext, we want to create each of our variable in order to be able to use the advance_time_matvecmul function. We already have epsilon established earlier, so we just need A and u. Because we want to see the development of the grid with each update, we want to create a list to append the u at different iterations. Thus, we will use the following block of code:\n\nA = get_A(N)\nu = u0\nu_array = []\n\n# Starting execution time for iterations\nstart_time = time.time()\n\nfor i in range(1,iters+1):\n  u = advance_time_matvecmul(A, u, epsilon)             # Updating our heatmap grid\n  if i % 300 == 0:\n    u_array.append(u.copy())                            # Appending every 300-th heatmap grid\n\n# Calculating iteration time\nexecution_time = time.time() - start_time\nprint(\"Execution Time is \", execution_time, \" seconds\")\n\nExecution Time is  233.45097470283508  seconds\n\n\nThis approach took quite a long time, taking almost 4 minutes to go through 2700 iterations.\nAlso note that through the conditional statement, we only appended 9 versions of u. With this appended list, we can now visualize the diffusion heatmaps. Because we have 9 grids, we can do 3x3 subplots by using pyplot through the following block of code:\n\ndef diffusion_visualization(list):\n  \"\"\"Generating a visualization of the 9 developed heatmap grids\n  Args:\n      list: list of appended heatmap grids\n\n  Returns:\n      3 rows, 3 columns of subplots of the heatmap grids\n  \"\"\"\n  # Generating base subplots\n  fig, ax = plt.subplots(3, 3, figsize = (12, 12))\n\n  # Creating indexing counter for list\n  count = 0\n\n  # Looping through row\n  for i in range(3):\n    # Looping through column\n    for j in range(3):\n      # Plotting/Showing the nth item in the list\n      ax[i][j].imshow(list[count])\n      # Setting title of the nth item in the list\n      ax[i][j].set_title(f\"{(count+1)*300}th iteration\")\n      # Iterator\n      count += 1\n\n  plt.tight_layout()\n  plt.show()\n\nGreat! Now that we have our diffusion heat visualization function, let’s run it using our list of wanted iterations.\n\ndiffusion_visualization(u_array)\n\n\n\n\n\n\n\n\nNotice that as more iterations occur, the heatmap develops, becoming more vibrant with the circles getting wider (exactly what we want).\n\n\nSparse Matrix in JAX\nNow that we have our initial method down, let’s use another method to increase computational time. For this one, we will use sparse matrices from JAX, a Python library designed for high-performance numerical computing.\nSo first, we need to import the following:\n\nimport jax\nfrom jax.experimental import sparse           # Allowing us to create sparse matrices\nimport jax.numpy as jnp                       # Allowing us to utilize jax numpy\nfrom jax import jit                           # Allowing us to use Just-In-Time compilations\n                                              # to execute JAX function effectively\n\n\nThe next step we want to do is create a function to output us a sparse matrix. Because we already have the function get_A to help us output a finite difference matrix, we can use call get_A in this function to create the array A, which we will then turn into a JAX numpy sparse array. We can do that with the following block of code:\n\nfrom heat_equation import get_sparse_A\nimport inspect\nprint(inspect.getsource(get_sparse_A))\n\ndef get_sparse_A(N):\n  \"\"\" Advancing simulation through BCOO (JAX batched coordimate)\n  to create sparse updating matrix\n\n  Args:\n    N: size of array\n  Returns:\n    an N x N sparse updating matrix\n  \"\"\"\n\n  # Creating updating matrix\n  A = get_A(N)\n  # Transforming A into JAX numpy array\n  jnp_A = jnp.array(A)\n  # Converting into sparse matrix\n  A_sp_matrix = sparse.BCOO.fromdense(jnp_A)\n  return A_sp_matrix\n\n\n\nNow that we have our new sparse matrix, we can repeat the process of iteration and visualization. However, we also want to use the jit-ed version of advance_time_matvecmul to execute the JAX numpys for effectively. Thus our code should look something like this:\n\n# Getting elements for advance_time function and iteration for loop\nA_sp_matrix = get_sparse_A(N)\nu = u0\nu_array_sparse = []\n\n# Using JIT compilation for advance_time function\njitted_advance_time_matvecmul = jax.jit(advance_time_matvecmul)\n\nstart_time = time.time()\n\nfor i in range(1,iters+1):\n  u = jitted_advance_time_matvecmul(A_sp_matrix, u, epsilon)\n  if i % 300 ==0:\n    u_array_sparse.append(u.copy())\n\nexecution_time = time.time() - start_time\nprint(\"Execution Time is \", execution_time, \" seconds\")\n\ndiffusion_visualization(u_array_sparse)\n\nExecution Time is  1.3260242938995361  seconds\n\n\n\n\n\n\n\n\n\nNotice that this function is MUCH faster than the first process! It took only 1.33 seconds.\n\n\nDirect Operation with Numpy\nFor this method, rather than relying on an updating matrix, we can update matrix u itself by using numpy’s vectorized array operations.\nTherefore, we will create an updated version of advance_time_vatmecmul that only needs two parameters: u and epsilon.\nAgain, we want our function to execute the updating equation above. Except this time. Rather than writing a matrix to represent the paranthetical part. we can use numpy to represent each u[i+1][j], u[i-1][j], u[i][j+1], u[i][j-1].\nWe can do this with using np.roll(), where we shift each of the points either left/right or up/down, depending on which we need. However, an important factor of np.roll() that we need to know is that it also takes the last point in the array and makes it the first and vice versa, which we don’t want. Thus we need to pad our array with 0 along the edge to prevent this. Thus our code should look something like this:\n\nfrom heat_equation import advance_time_numpy\nimport inspect\nprint(inspect.getsource(advance_time_numpy))\n\ndef advance_time_numpy(u, epsilon):\n  \"\"\"Advances the simulation by one timestep, via numpy rolling\n    Args:\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n  \"\"\"\n\n  # Creating padded version of u with 0's along edge\n  padded_u = np.pad(u, 1, mode = 'constant')\n\n  # Creating rolled version of padded u\n  right_roll = np.roll(padded_u, 1, axis = 1)\n  left_roll = np.roll(padded_u, -1, axis = 1)\n  up_roll = np.roll(padded_u, -1, axis = 0)\n  down_roll = np.roll(padded_u, 1, axis = 0)\n\n  # Updating u\n  numpy_u = padded_u + epsilon*(right_roll + left_roll + up_roll + down_roll - (4*padded_u))\n  # Removing the 0's on the edge\n  numpy_u_sliced = numpy_u[1:-1, 1:-1]\n  return numpy_u_sliced\n\n\n\nNotice that before returning the updated u, we used sliced indexing because the padded u is a (N+2) x (N+2) array, but we only want a N x N array.\nWith this function, we can again run our iterations and visualization and see how long this takes.\n\nnumpy_u = u0\nresults_numpy = []\n\nstart_time = time.time()\n\nfor i in range(1,iters+1):\n  numpy_u = advance_time_numpy(numpy_u, epsilon)\n  if i % 300 ==0:\n    results_numpy.append(numpy_u.copy())\n\nexecution_time = time.time() - start_time\nprint(\"Execution Time is \", execution_time, \" seconds\")\n\ndiffusion_visualization(results_numpy)\n\nExecution Time is  0.522552490234375  seconds\n\n\n\n\n\n\n\n\n\nThis time, it only takes 0.52 seconds, 2.3 times as fast!\n\n\nJAX\nThe last method we will use is jax, similar to when we did sparse matrix, we will do an jax version of the previous function, which will allow us to use just-in-time compilation. Benefit of this method as well is that we will not need to rely on (sparse) matrix multiplication.\nEverything will be the same as advance_time_numpy, but we just replace all the numpy with jax.numpy, or jnp. Thus we should get the following code:\n\nfrom heat_equation import advance_time_jax\nimport inspect\nprint(inspect.getsource(advance_time_jax))\n\ndef advance_time_jax(u, epsilon):\n  \"\"\"Advances the simulation by one timestep, via jax numpy rolling\n  Args:\n      u: N x N grid state at timestep k.\n      epsilon: stability constant.\n\n  Returns:\n      N x N Grid state at timestep k+1.\n  \"\"\"\n\n  # Creating padded version of u with 0's along edge\n  padded_u = jnp.pad(u, 1, mode = 'constant')\n\n  # Creating rolled version of padded u\n  right_roll = jnp.roll(padded_u, 1, axis = 1)\n  left_roll = jnp.roll(padded_u, -1, axis = 1)\n  up_roll = jnp.roll(padded_u, -1, axis = 0)\n  down_roll = jnp.roll(padded_u, 1, axis = 0)\n\n  # Updating u\n  jnp_u = padded_u + epsilon*(right_roll + left_roll + up_roll + down_roll - (4*padded_u))\n  # Removing the 0's on the edge\n  jnp_u_sliced = jnp_u[1:-1, 1:-1]\n  return jnp_u_sliced\n\n\n\nFor one last time, we will run our iteration and visualization. Because we are dealing with jax numpy again, we will use the jit-ed version of advance_time_jax.\n\njitted_jax = jax.jit(advance_time_jax)\njnp_u = u0\nresults_jnp = []\n\nstart_time = time.time()\n\nfor i in range(1,iters+1):\n  jnp_u = jitted_jax(jnp_u, epsilon)\n  if i % 300 ==0:\n    results_jnp.append(jnp_u.copy())\n\nexecution_time = time.time() - start_time\nprint(\"Execution Time is \", execution_time, \" seconds\")\n\ndiffusion_visualization(results_jnp)\n\nExecution Time is  0.08782696723937988  seconds\n\n\n\n\n\n\n\n\n\nThis one is the fastest of them all, taking 0.09 seconds, more than 5 times as fast as the previous one!\n\n\nComparison\nOut of all of these, the fastest is of course with jax as it took only 0.09 seconds, followed by direct operation through numpy, then sparse matrix, and lastly direct matrix multiplication.\nOut of all of these, I think that direct operation through nunmpy was the easiest to write since it did not require me to write two functions, and I did not have to use an additional updating matrix, which got really complicated."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pic16bblog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 4: Matrix Multiplication and Jax Numpy (Heat Diffusion)\n\n\n\n\n\n\nweek 7\n\n\nHomework\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nThomas Nguyen\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]